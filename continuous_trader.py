#!/usr/bin/env python3
"""
AlphaBeta808 Continuous Trading Bot
Trading continu 24h/24 7j/7 avec gestion automatique du portfolio
"""

import os
import sys
import time
import asyncio
import logging
import signal
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Callable
import pandas as pd
import numpy as np
from dotenv import load_dotenv
import json
import joblib

# Ajout du r√©pertoire src au sys.path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), 'src')))

# Imports des modules existants
from src.acquisition.connectors import load_binance_klines
from src.feature_engineering.technical_features import (
    calculate_sma, calculate_ema, calculate_rsi,
    calculate_macd, calculate_bollinger_bands,
    calculate_price_momentum, calculate_volume_features
)
from src.modeling.models import prepare_data_for_model, load_model_and_predict
from src.signal_generation.signal_generator import generate_base_signals_from_predictions
from src.execution.real_time_trading import (
    BinanceRealTimeTrader, TradingStrategy, RiskManager,
    MarketData, TradingOrder, OrderSide, OrderType, OrderStatus
)
from src.portfolio.multi_asset import MultiAssetPortfolioManager

# Configuration du logging avec gestion des syst√®mes de fichiers en lecture seule
def setup_logging():
    handlers = [logging.StreamHandler()]
    
    # Essayer d'ajouter un FileHandler si possible
    try:
        os.makedirs('logs', exist_ok=True)
        handlers.append(logging.FileHandler('logs/continuous_trader.log'))
    except (OSError, PermissionError) as e:
        print(f"Warning: Cannot create log file (read-only filesystem?): {e}")
        print("Logging to console only")
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=handlers
    )

setup_logging()
logger = logging.getLogger(__name__)

class ContinuousTrader:
    """
    Bot de trading continu 24h/24 7j/7
    Scanne les opportunit√©s, g√©n√®re des signaux et ex√©cute les trades automatiquement
    """
    
    def __init__(self, config_file: str = "trader_config.json"):
        """
        Initialize the continuous trader
        
        Args:
            config_file: Path to configuration file
        """
        self.config = self._load_config(config_file)
        self.is_running = False
        self.trader = None
        self.strategy = None
        self.portfolio_manager = None
        self.risk_manager = None
        
        # √âtat du trading
        self.last_model_update = None # Conserver pour la logique de _should_update_model
        self.trading_pairs = self.config.get('trading_pairs', ['BTCUSDT', 'ETHUSDT', 'ADAUSDT'])
        self.scan_interval = self.config.get('scan_interval', 60)  # seconds
        self.model_update_interval = self.config.get('model_update_interval', 3600)  # 1 heure
        
        # Historique de march√© pour les features
        self.market_history: Dict[str, pd.DataFrame] = {} # Symbol -> DataFrame
        self.last_feature_update: Dict[str, datetime] = {}

        # M√©triques de performance et statistiques
        self.stats = {
            'start_time': datetime.now(),
            'total_signals_generated': 0,
            'total_signals_processed': 0,
            'total_trades_executed': 0, # Compte les soumissions d'ordres
            'successful_trades': 0, # Compte les ordres FILLED
            'failed_trades': 0, # Compte les ordres REJECTED, CANCELED, EXPIRED ou √©checs de soumission
            'errors': 0,
            'pnl_today': 0.0, # Profit and Loss journalier
            'last_health_check': None,
            'last_model_retrain_time': None,
            'current_exposure': 0.0,
            'open_positions': {} # symbol -> {quantity, entry_price_sum}
        }
        # Pour compatibilit√© avec le code existant qui pourrait utiliser ces attributs directement
        self.trades_today = 0
        self.profit_loss_today = 0.0
        self.start_time = self.stats['start_time']

        # Queue pour les signaux de trading
        self.signal_queue = asyncio.Queue()
        
        logger.info("ContinuousTrader initialis√©")
    
    def _load_config(self, config_file: str) -> Dict:
        """Charge la configuration depuis un fichier JSON"""
        default_config = {
            "initial_capital": 10000,
            "max_position_size": 0.1, # Pourcentage du capital total par position
            "max_daily_loss": 0.02, # Pourcentage du capital initial
            "max_total_exposure": 0.8, # Pourcentage du capital total investi
            "trading_pairs": ["BTCUSDT", "ETHUSDT", "ADAUSDT", "BNBUSDT", "SOLUSDT"],
            "scan_interval": 60, # secondes, pour _market_scanner
            "model_update_interval": 3600, # secondes, pour _model_updater
            "testnet": True, # true pour le mode testnet de Binance, false pour production

            "model": {
                "ensemble_enabled": True,
                "models": [
                    {
                        "name": "logistic_regression",
                        "path": "models_store/logistic_regression_mvp.joblib",
                        "weight": 0.3,
                        "enabled": True
                    },
                    {
                        "name": "elastic_net",
                        "path": "models_store/test_elasticnet_model.joblib",
                        "weight": 0.2,
                        "enabled": True
                    },
                    {
                        "name": "random_forest",
                        "path": "models_store/test_rf_opt_model.joblib",
                        "weight": 0.25,
                        "enabled": True
                    },
                    {
                        "name": "xgboost",
                        "path": "models_store/test_xgb_opt_model.joblib",
                        "weight": 0.25,
                        "enabled": True
                    }
                ],
                "fallback_model": "models_store/logistic_regression_mvp.joblib",
            },

            "trading_thresholds": {
                "buy_threshold": 0.3,
                "sell_threshold": -0.3
            },

            "signal_filters": {
                "enabled": True,
                "volatility": { # Filtre bas√© sur la variation de prix sur 24h
                    "max_change_percent_24h": 10.0, # Si > 10% de variation, signal att√©nu√©
                    "signal_dampening_factor": 0.5
                },
                "spread": { # Filtre bas√© sur le spread bid-ask (n√©cessite donn√©es temps r√©el non kline)
                    "max_relative_spread": 0.001, # Si spread > 0.1%, signal att√©nu√©
                    "signal_dampening_factor": 0.7,
                    "enabled": False # D√©sactiv√© par d√©faut car n√©cessite appel API suppl√©mentaire
                },
                "volume": { # Filtre bas√© sur le volume de trading sur 24h
                    "min_volume_24h_usdt": 1000000, # Volume en USDT pour comparaison entre paires
                    "signal_boost_factor": 1.1, # Si volume suffisant, signal renforc√©
                    "use_kline_volume_proxy": True # Si true et volume 24h non dispo, utilise volume de la kline * prix comme proxy
                }
            },

            "risk_management": {
                "stop_loss_percent": 0.02,
                "take_profit_percent": 0.04,
                "max_orders_per_minute": 10
            },

            "features": {
                "sma_windows": [10, 20, 50],
                "ema_windows": [10, 20],
                "rsi_window": 14,
                "use_volume_features": True,
                "feature_lookback_periods": 200 # Nombre de klines √† conserver pour calcul des features
            },
            "logging": {
                "level": "INFO",
                "file": "continuous_trader.log"
            }
        }
        
        if os.path.exists(config_file):
            try:
                with open(config_file, 'r') as f:
                    loaded_config = json.load(f)
                
                # Deep merge for nested dictionaries
                def deep_update(source, overrides):
                    for key, value in overrides.items():
                        if isinstance(value, dict) and key in source and isinstance(source[key], dict):
                            deep_update(source[key], value)
                        else:
                            source[key] = value
                    return source

                default_config = deep_update(default_config, loaded_config)
                logger.info(f"Configuration charg√©e depuis {config_file}")
            except Exception as e:
                logger.warning(f"Erreur lors du chargement de {config_file}: {e}")
                logger.info("Utilisation de la configuration par d√©faut")
        else:
            # Cr√©er le fichier de configuration par d√©faut
            with open(config_file, 'w') as f:
                json.dump(default_config, f, indent=4)
            logger.info(f"Fichier de configuration par d√©faut cr√©√©: {config_file}")
        
        return default_config
    
    async def initialize(self):
        """Initialise tous les composants du trader"""
        try:
            load_dotenv()
            
            # V√©rifier les cl√©s API
            api_key = os.getenv('BINANCE_API_KEY')
            api_secret = os.getenv('BINANCE_API_SECRET')
            
            if not api_key or not api_secret:
                raise ValueError("Cl√©s API Binance manquantes dans les variables d'environnement")
            
            # Initialiser le risk manager
            self.risk_manager = RiskManager(
                max_position_size=self.config['max_position_size'],
                max_daily_loss=self.config['max_daily_loss'],
                max_total_exposure=self.config['max_total_exposure'],
                max_orders_per_minute=self.config['risk_management']['max_orders_per_minute']
            )
            
            # Initialiser le trader Binance
            self.trader = BinanceRealTimeTrader(
                api_key=api_key,
                api_secret=api_secret,
                testnet=self.config.get('testnet', True), # Utiliser la configuration
                risk_manager=self.risk_manager
            )
            
            # Initialiser le portfolio manager
            self.portfolio_manager = MultiAssetPortfolioManager(
                initial_capital=self.config['initial_capital']
            )
            
            # Initialiser la strat√©gie de trading
            self.strategy = TradingStrategy(self.trader)
            
            # Configurer les callbacks
            self.trader.set_callbacks(
                on_market_data=self._on_market_data,
                on_order_update=self._on_order_update,
                on_account_update=self._on_account_update
            )
            
            # Ajouter les paires de trading √† la strat√©gie
            for symbol in self.trading_pairs:
                self.strategy.add_symbol(symbol)
            
            logger.info("Tous les composants ont √©t√© initialis√©s avec succ√®s")
            
        except Exception as e:
            logger.error(f"Erreur lors de l'initialisation: {e}")
            raise
    
    async def start_trading(self):
        """D√©marre le trading continu"""
        if self.is_running:
            logger.warning("Le trading est d√©j√† en cours")
            return
        
        self.is_running = True
        logger.info("üöÄ D√©marrage du trading continu AlphaBeta808...")
        
        try:
            # D√©marrer les t√¢ches asynchrones
            tasks = [
                asyncio.create_task(self._market_scanner()),
                asyncio.create_task(self._signal_processor()),
                asyncio.create_task(self._model_updater()),
                asyncio.create_task(self._performance_monitor()),
                asyncio.create_task(self._risk_monitor())
            ]
            
            # D√©marrer le flux de donn√©es de march√©
            self.strategy.start_trading(self.trading_pairs)
            
            # Attendre que toutes les t√¢ches soient termin√©es
            await asyncio.gather(*tasks)
            
        except Exception as e:
            logger.error(f"Erreur dans le trading continu: {e}")
            await self.stop_trading()
    
    async def stop_trading(self):
        """Arr√™te le trading continu"""
        if not self.is_running:
            return
        
        self.is_running = False
        logger.info("üõë Arr√™t du trading continu...")
        
        try:
            # Arr√™ter la strat√©gie
            if self.strategy:
                self.strategy.stop_trading()
            
            # Annuler tous les ordres ouverts
            if self.trader:
                await self._cancel_all_open_orders()
            
            logger.info("Trading arr√™t√© avec succ√®s")
            
        except Exception as e:
            logger.error(f"Erreur lors de l'arr√™t: {e}")
    
    async def _market_scanner(self):
        """Scanne les march√©s en continu pour d√©tecter les opportunit√©s"""
        logger.info("üì° D√©marrage du scanner de march√©")
        
        while self.is_running:
            try:
                for symbol in self.trading_pairs:
                    await self._analyze_symbol(symbol)
                
                # Attendre avant le prochain scan
                await asyncio.sleep(self.scan_interval)
                
            except Exception as e:
                logger.error(f"Erreur dans le scanner de march√©: {e}")
                await asyncio.sleep(30)  # Attendre un peu plus en cas d'erreur
    
    async def _analyze_symbol(self, symbol: str):
        """Analyse un symbole sp√©cifique et g√©n√®re un signal"""
        try:
            min_lookback_features = self.config['features'].get('feature_lookback_periods', 200)
            # Un seuil minimal absolu pour avoir assez de donn√©es pour les indicateurs (ex: RSI 14 + MACD ~26-30)
            # On prend le max des fen√™tres de SMA/EMA/RSI etc. + une marge.
            # Pour RSI(14), EMA(20), SMA(50), il faut au moins 50 points.
            # min_data_points_for_features = max(
            #     max(self.config['features']['sma_windows'] if self.config['features']['sma_windows'] else [0]),
            #     max(self.config['features']['ema_windows'] if self.config['features']['ema_windows'] else [0]),
            #     self.config['features']['rsi_window']
            # ) + 20 # Marge pour stabilisation des indicateurs
            min_data_points_for_features = 70 # Valeur fixe pour simplifier, bas√©e sur SMA50 + marge

            market_data_df = None
            use_history = False
            if symbol in self.market_history and len(self.market_history[symbol]) >= min_data_points_for_features:
                # V√©rifier si la derni√®re donn√©e de l'historique est suffisamment r√©cente
                # Cela d√©pend de la fr√©quence des klines re√ßues par _on_market_data
                # Si on scan toutes les minutes et qu'on re√ßoit des klines 1m, c'est bon.
                # Si on scan toutes les heures et qu'on re√ßoit des klines 1h, c'est bon.
                # Pour l'instant, on suppose que si l'historique est l√†, il est pertinent.
                market_data_df = self.market_history[symbol].copy()
                use_history = True
                logger.debug(f"Utilisation de l'historique de march√© pour {symbol} ({len(market_data_df)} points)")
            
            if not use_history:
                logger.debug(f"R√©cup√©ration de nouvelles donn√©es de march√© pour {symbol} (historique insuffisant ou trop ancien)")
                # S'assurer de r√©cup√©rer assez de donn√©es pour le calcul des features + la p√©riode de lookback du mod√®le si besoin.
                # min_lookback_features est pour le calcul des features.
                market_data_df = await self._get_recent_market_data(symbol, limit=min_lookback_features + 50) # +50 pour marge

            if market_data_df is None or len(market_data_df) < min_data_points_for_features:
                logger.warning(f"Donn√©es insuffisantes pour {symbol} apr√®s r√©cup√©ration/historique ({len(market_data_df) if market_data_df is not None else 0} points, besoin de {min_data_points_for_features}).")
                return
            
            # Calculer les features techniques
            required_cols = ['open', 'high', 'low', 'close', 'volume'] # Assurer que ces colonnes existent
            if not all(col in market_data_df.columns for col in required_cols):
                logger.warning(f"Colonnes OHLVC manquantes pour {symbol}. Tentative de r√©cup√©ration compl√®te.")
                market_data_df = await self._get_recent_market_data(symbol, limit=min_lookback_features + 50)
                if market_data_df is None or not all(col in market_data_df.columns for col in required_cols):
                    logger.error(f"√âchec final de r√©cup√©ration des colonnes OHLVC pour {symbol}.")
                    return

            market_data_with_features = self._calculate_features(market_data_df.copy()) # Toujours copier
            
            if market_data_with_features.empty or len(market_data_with_features) < 1: # S'assurer qu'il y a au moins une ligne apr√®s dropna
                logger.warning(f"Donn√©es vides apr√®s calcul des features pour {symbol}")
                return

            # G√©n√©rer une pr√©diction avec le mod√®le
            signal_strength = await self._generate_signal(market_data_with_features, symbol)
            self.stats['total_signals_generated'] += 1
            
            if signal_strength is not None:
                current_price = market_data_with_features['close'].iloc[-1]
                last_row_dict = market_data_with_features.iloc[-1].to_dict()

                # Tenter de r√©cup√©rer des donn√©es de ticker plus r√©centes pour les filtres (volume 24h, etc.)
                # Ceci est optionnel et ajoute un appel API.
                ticker_info = None
                try:
                    # Note: get_ticker_info n'est pas async dans BinanceRealTimeTrader,
                    # il faudrait l'adapter ou utiliser une version non-bloquante si disponible.
                    # Pour l'instant, on va supposer qu'on ne fait pas cet appel ici pour garder _analyze_symbol sync apr√®s les await initiaux.
                    # Les filtres devront se contenter des donn√©es des klines.
                    # Si BinanceRealTimeTrader.get_ticker_info() devient async:
                    # ticker_info = await self.trader.get_ticker_info(symbol)
                    pass
                except Exception as e_ticker:
                    logger.warning(f"Impossible de r√©cup√©rer les infos du ticker pour {symbol} pour les filtres: {e_ticker}")

                market_snapshot_for_filter = last_row_dict.copy()
                if ticker_info:
                    # 'priceChangePercent' est utile pour le filtre de volatilit√©
                    market_snapshot_for_filter['price_change_percent_24h'] = float(ticker_info.get('priceChangePercent', 0.0))
                    # 'quoteVolume' est le volume en USDT sur 24h, utile pour le filtre de volume
                    market_snapshot_for_filter['volume_usdt_24h'] = float(ticker_info.get('quoteVolume', 0.0))
                    # 'askPrice', 'bidPrice' pour le filtre de spread
                    market_snapshot_for_filter['ask_price'] = float(ticker_info.get('askPrice', 0.0))
                    market_snapshot_for_filter['bid_price'] = float(ticker_info.get('bidPrice', 0.0))
                else:
                    # Si pas de ticker_info, les filtres devront s'adapter ou utiliser des proxies
                    # Le volume de la kline est dans last_row_dict['volume'] et last_row_dict['quote_asset_volume']
                    pass


                signal_payload = {
                    'symbol': symbol,
                    'signal': signal_strength,
                    'timestamp': datetime.now(),
                    'price': current_price,
                    'market_data_snapshot': market_snapshot_for_filter
                }
                await self.signal_queue.put(signal_payload)
                
                logger.debug(f"Signal g√©n√©r√© pour {symbol}: {signal_strength:.3f} @ {current_price}")
        
        except Exception as e:
            logger.error(f"Erreur lors de l'analyse de {symbol}: {e}")
            self.stats['errors'] += 1
    
    async def _get_recent_market_data(self, symbol: str, limit: int = 100) -> Optional[pd.DataFrame]:
        """R√©cup√®re les donn√©es de march√© r√©centes pour un symbole"""
        try:
            # Utiliser l'API Binance pour r√©cup√©rer les klines r√©centes
            api_key = os.getenv('BINANCE_API_KEY')
            api_secret = os.getenv('BINANCE_API_SECRET')
            
            # R√©cup√©rer les 100 derni√®res bougies 1h
            market_data_dict = load_binance_klines(
                api_key=api_key,
                api_secret=api_secret,
                symbol=symbol,
                intervals=['1h'],
                start_date_str="7 days ago"
            )
            
            if '1h' in market_data_dict:
                return market_data_dict['1h']
            
            return None
            
        except Exception as e:
            logger.error(f"Erreur lors de la r√©cup√©ration des donn√©es pour {symbol}: {e}")
            return None
    
    def _calculate_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """Calcule les features techniques sur les donn√©es"""
        try:
            # Features de base - exactement celles attendues par les mod√®les
            # G√©n√©rer toutes les features SMA et EMA requises
            data = calculate_sma(data, column='close', windows=[10, 20])  # Pour avoir sma_10, sma_20
            data = calculate_ema(data, column='close', windows=[10, 20])  # Pour avoir ema_10, ema_20
            data = calculate_rsi(data, column='close', window=14)         # Pour avoir rsi_14
            
            # MACD avec tous les composants
            data = calculate_macd(data, column='close')  # Pour avoir macd, macd_signal, macd_hist
            
            # Bollinger Bands
            data = calculate_bollinger_bands(data, column='close')  # Pour avoir bb_upper, bb_lower, bb_position
            
            # Price momentum avec les fen√™tres requises
            data = calculate_price_momentum(data, column='close', windows=[5, 10])  # Pour avoir momentum_5, volatility_5, momentum_10, volatility_10
            
            # Features de volume si activ√©es (toujours activ√©es pour correspondre aux mod√®les)
            if 'volume' in data.columns:
                data = calculate_volume_features(data, volume_col='volume', price_col='close')  # Pour avoir volume_sma_10, volume_ratio_10, volume_sma_20, volume_ratio_20, vwap_10
            
            # Nettoyer les NaN
            data = data.dropna()
            
            return data
            
        except Exception as e:
            logger.error(f"Erreur lors du calcul des features: {e}")
            return data
    
    async def _generate_signal(self, data: pd.DataFrame, symbol: str) -> Optional[float]:
        """G√©n√®re un signal de trading bas√© sur un ensemble de mod√®les ML"""
        try:
            # Calculer la feature 'other_feature' qui manque pour certains mod√®les
            if 'other_feature' not in data.columns:
                data['other_feature'] = (data['close'] - data['close'].shift(5)) / data['close'].shift(5) * 100
                data = data.dropna()  # Nettoyer les NaN apr√®s ajout de other_feature
            
            # Syst√®me d'ensemble de mod√®les
            ensemble_enabled = self.config['model'].get('ensemble_enabled', False)
            
            if ensemble_enabled and 'models' in self.config['model']:
                # Utiliser l'ensemble de mod√®les
                predictions = []
                weights = []
                
                for model_config in self.config['model']['models']:
                    if not model_config.get('enabled', True):
                        continue
                        
                    model_path = model_config['path']
                    model_weight = model_config.get('weight', 1.0)
                    
                    if not os.path.exists(model_path):
                        logger.warning(f"Mod√®le non trouv√©: {model_path} (ignor√©)")
                        continue
                    
                    try:
                        # Charger le mod√®le pour d√©terminer les features attendues
                        import joblib
                        model_data = joblib.load(model_path)
                        expected_features = model_data.get('feature_columns', [])
                        
                        # V√©rifier que toutes les features attendues sont pr√©sentes
                        missing_features = [f for f in expected_features if f not in data.columns]
                        if missing_features:
                            logger.error(f"Features manquantes pour {model_config['name']}: {missing_features}")
                            logger.error(f"Features disponibles: {list(data.columns)}")
                            continue
                        
                        # Utiliser seulement les features attendues par ce mod√®le et la derni√®re observation
                        X = data[expected_features].iloc[-1:].copy()
                        
                        logger.debug(f"Features utilis√©es pour {model_config['name']}: {list(X.columns)}")
                        
                        prediction = load_model_and_predict(X, model_path=model_path, return_probabilities=True)
                        
                        if prediction is not None and len(prediction) > 0:
                            predictions.append(prediction[0])
                            weights.append(model_weight)
                            logger.debug(f"Pr√©diction {model_config['name']}: {prediction[0]:.3f}")
                        
                    except Exception as e:
                        logger.error(f"Erreur avec le mod√®le {model_config['name']}: {e}")
                        continue
                
                if len(predictions) > 0:
                    # Valider que toutes les pr√©dictions sont des nombres valides
                    valid_predictions = []
                    valid_weights = []
                    for i, pred in enumerate(predictions):
                        if not np.isnan(pred) and not np.isinf(pred):
                            valid_predictions.append(pred)
                            valid_weights.append(weights[i])
                        else:
                            logger.warning(f"Pr√©diction invalide ignor√©e pour {symbol}: {pred}")
                    
                    if len(valid_predictions) == 0:
                        logger.warning(f"Toutes les pr√©dictions sont invalides (NaN/Inf) pour {symbol}")
                        return None
                    
                    # Calculer la pr√©diction pond√©r√©e
                    weighted_pred = np.average(valid_predictions, weights=valid_weights)
                    
                    # V√©rifier que la pr√©diction pond√©r√©e est valide
                    if np.isnan(weighted_pred) or np.isinf(weighted_pred):
                        logger.error(f"Pr√©diction pond√©r√©e invalide pour {symbol}: {weighted_pred}")
                        return None
                    
                    # Ajouter quelques m√©triques d'ensemble
                    std_pred = np.std(valid_predictions) if len(valid_predictions) > 1 else 0.0
                    min_pred = np.min(valid_predictions)
                    max_pred = np.max(valid_predictions)
                    
                    logger.debug(f"Ensemble pour {symbol}: avg={weighted_pred:.3f}, std={std_pred:.3f}, min={min_pred:.3f}, max={max_pred:.3f}")
                    
                    # Convertir la probabilit√© en signal (-1 √† 1)
                    signal = (weighted_pred - 0.5) * 2  # Map [0,1] to [-1,1]
                    
                    # Valider le signal final
                    if np.isnan(signal) or np.isinf(signal):
                        logger.error(f"Signal final invalide pour {symbol}: {signal}")
                        return None
                    
                    # R√©duire le signal si la variance est √©lev√©e (incertitude)
                    if std_pred > 0.2:  # Si √©cart-type > 20%
                        uncertainty_factor = max(0.5, 1.0 - std_pred)
                        signal *= uncertainty_factor
                        logger.debug(f"Signal r√©duit pour incertitude: {signal:.3f} (facteur: {uncertainty_factor:.3f})")
                    
                    # Validation finale du signal
                    if np.isnan(signal) or np.isinf(signal):
                        logger.error(f"Signal final apr√®s ajustement invalide pour {symbol}: {signal}")
                        return None
                    
                    return signal
                else:
                    logger.warning(f"Aucun mod√®le n'a pu g√©n√©rer de pr√©diction pour {symbol}")
                    # Fallback vers le mod√®le par d√©faut
                    fallback_path = self.config['model'].get('fallback_model', 'models_store/logistic_regression_mvp.joblib')
                    if os.path.exists(fallback_path):
                        prediction = load_model_and_predict(X, model_path=fallback_path, return_probabilities=True)
                        if prediction is not None and len(prediction) > 0:
                            # Valider la pr√©diction du mod√®le de fallback
                            if not np.isnan(prediction[0]) and not np.isinf(prediction[0]):
                                signal = (prediction[0] - 0.5) * 2
                                # Validation finale du signal de fallback
                                if not np.isnan(signal) and not np.isinf(signal):
                                    logger.info(f"Utilisation du mod√®le de fallback pour {symbol}: {signal:.3f}")
                                    return signal
                                else:
                                    logger.error(f"Signal de fallback invalide pour {symbol}: {signal}")
                            else:
                                logger.error(f"Pr√©diction de fallback invalide pour {symbol}: {prediction[0]}")
                    return None
                    
            else:
                # Mode mod√®le unique (ancien comportement)
                model_path = self.config['model'].get('model_path', 'models_store/logistic_regression_mvp.joblib')
                if not os.path.exists(model_path):
                    logger.warning(f"Mod√®le non trouv√©: {model_path}")
                    return None
                
                prediction = load_model_and_predict(X, model_path=model_path, return_probabilities=True)
                
                if prediction is not None and len(prediction) > 0:
                    # Valider la pr√©diction du mod√®le unique
                    if not np.isnan(prediction[0]) and not np.isinf(prediction[0]):
                        # Convertir la probabilit√© en signal (-1 √† 1)
                        prob = prediction[0]
                        signal = (prob - 0.5) * 2  # Map [0,1] to [-1,1]
                        
                        # Validation finale du signal
                        if not np.isnan(signal) and not np.isinf(signal):
                            return signal
                        else:
                            logger.error(f"Signal final invalide pour {symbol}: {signal}")
                            return None
                    else:
                        logger.error(f"Pr√©diction invalide du mod√®le unique pour {symbol}: {prediction[0]}")
                        return None
            
            return None
            
        except Exception as e:
            logger.error(f"Erreur lors de la g√©n√©ration du signal pour {symbol}: {e}")
            return None
    
    async def _signal_processor(self):
        """Traite les signaux de trading en continu"""
        logger.info("üìä D√©marrage du processeur de signaux")
        
        while self.is_running:
            try:
                # R√©cup√©rer un signal de la queue (avec timeout)
                try:
                    signal_data = await asyncio.wait_for(self.signal_queue.get(), timeout=1.0)
                except asyncio.TimeoutError:
                    continue
                
                # Traiter le signal
                await self._process_trading_signal(signal_data)
                
            except Exception as e:
                logger.error(f"Erreur dans le processeur de signaux: {e}")
                await asyncio.sleep(1)
    
    async def _process_trading_signal(self, signal_data: Dict):
        """Traite un signal de trading individuel"""
        try:
            symbol = signal_data['symbol']
            original_signal = signal_data['signal']
            price = signal_data['price'] # Prix au moment de la g√©n√©ration du signal
            market_snapshot = signal_data.get('market_data_snapshot', {}) # Donn√©es de la derni√®re bougie

            # Validation initiale du signal pour NaN/Inf
            if original_signal is None or np.isnan(original_signal) or np.isinf(original_signal):
                logger.warning(f"Signal invalide ignor√© pour {symbol}: {original_signal}")
                return

            # Validation du prix pour NaN/Inf
            if price is None or np.isnan(price) or np.isinf(price):
                logger.warning(f"Prix invalide ignor√© pour {symbol}: {price}")
                return

            self.stats['total_signals_processed'] += 1
            
            # Appliquer les filtres de signaux
            filtered_signal = original_signal
            if self.config['signal_filters']['enabled']:
                filtered_signal = self._apply_signal_filters(symbol, original_signal, price, market_snapshot)
            
            # Validation du signal filtr√© pour NaN/Inf
            if filtered_signal is None or np.isnan(filtered_signal) or np.isinf(filtered_signal):
                logger.warning(f"Signal filtr√© invalide ignor√© pour {symbol}: {filtered_signal}")
                return

            if filtered_signal != original_signal:
                logger.info(f"Signal pour {symbol} filtr√© de {original_signal:.3f} √† {filtered_signal:.3f}")

            # Seuils de trading configurables
            buy_threshold = self.config['trading_thresholds']['buy_threshold']
            sell_threshold = self.config['trading_thresholds']['sell_threshold']
            
            # V√©rifier les limites de risque
            if not self._check_risk_limits(symbol, filtered_signal): # Utiliser le signal filtr√© pour la d√©cision de risque
                return
            
            # D√©terminer l'action √† prendre
            if filtered_signal > buy_threshold:
                await self._execute_buy_signal(symbol, filtered_signal, price)
            elif filtered_signal < sell_threshold:
                await self._execute_sell_signal(symbol, filtered_signal, price)
            
        except Exception as e:
            logger.error(f"Erreur lors du traitement du signal: {e}")
            self.stats['errors'] += 1
    
    def _apply_signal_filters(self, symbol: str, signal: float, current_price: float, market_snapshot: Dict) -> float:
        """Applique des filtres au signal g√©n√©r√©."""
        if not self.config['signal_filters']['enabled']:
            return signal

        cfg_filters = self.config['signal_filters']
        modified_signal = signal

        # 1. Filtre de Volatilit√©
        # N√©cessite price_change_24h. Si non dispo dans market_snapshot, on ne peut pas l'appliquer.
        # 'market_snapshot' vient des klines, qui n'ont pas directement price_change_24h.
        # On pourrait essayer de le calculer √† partir de l'historique, ou le r√©cup√©rer via un appel ticker.
        # Pour l'instant, si 'price_change_24h' n'est pas dans market_snapshot, on saute ce filtre.
        # Alternative: utiliser une mesure de volatilit√© bas√©e sur les klines (ex: ATR).
        # Simplification: si on a 'price_change_percent' dans market_snapshot (ex: si on l'ajoute depuis un ticker)
        price_change_24h_percent = market_snapshot.get('price_change_percent') # Supposons qu'on l'ait
        if price_change_24h_percent is not None:
            vol_cfg = cfg_filters.get('volatility', {})
            if abs(price_change_24h_percent) > vol_cfg.get('max_change_percent_24h', 10.0):
                modified_signal *= vol_cfg.get('signal_dampening_factor', 0.5)
                logger.debug(f"Filtre volatilit√© appliqu√© pour {symbol}. Signal: {modified_signal:.3f}")

        # 2. Filtre de Spread (Difficile sans donn√©es bid/ask en temps r√©el)
        # Les klines ne fournissent pas bid/ask. On pourrait le r√©cup√©rer via self.trader.get_order_book_ticker(symbol)
        # Pour l'instant, on va sauter ce filtre ou le rendre optionnel.
        # spread_cfg = cfg_filters.get('spread', {})
        # try:
        #     ticker_data = await self.trader.get_ticker_data(symbol) # N√©cessiterait que la m√©thode soit async
        #     if ticker_data and 'askPrice' in ticker_data and 'bidPrice' in ticker_data:
        #         ask_price = float(ticker_data['askPrice'])
        #         bid_price = float(ticker_data['bidPrice'])
        #         if current_price > 0: # current_price est le close de la kline, peut √™tre diff√©rent
        #             spread = (ask_price - bid_price) / current_price
        #             if spread > spread_cfg.get('max_relative_spread', 0.001):
        #                 modified_signal *= spread_cfg.get('signal_dampening_factor', 0.7)
        #                 logger.debug(f"Filtre spread appliqu√© pour {symbol}. Signal: {modified_signal:.3f}")
        # except Exception as e:
        #     logger.warning(f"Impossible d'appliquer le filtre de spread pour {symbol}: {e}")
        pass # Sauter le filtre de spread pour l'instant car il n√©cessite un appel async dans une m√©thode sync

        # 3. Filtre de Volume
        # 'volume' dans market_snapshot est le volume de la kline, pas le volume 24h en USD.
        # On a besoin du volume 24h en USDT (ou √©quivalent).
        # On pourrait le r√©cup√©rer via self.trader.get_ticker_data(symbol) -> quoteVolume
        # Ou si 'volume_usd_24h' est dans market_snapshot.
        volume_cfg = cfg_filters.get('volume', {})
        volume_24h_usd = market_snapshot.get('quote_asset_volume') # 'volume' est base asset, 'quote_asset_volume' est volume en quote (USDT)
                                                                # Ceci est le volume de la kline, pas 24h.
                                                                # Pour un vrai volume 24h, il faudrait un appel ticker.
        # Tentative d'utiliser le volume de la kline comme proxy si 'volume_24h_usd' n'est pas l√†.
        # C'est une approximation grossi√®re.
        if volume_24h_usd is None and 'volume' in market_snapshot and current_price > 0:
             volume_24h_usd = market_snapshot['volume'] * current_price # Approximation du volume de la kline en USD

        if volume_24h_usd is not None:
            if volume_24h_usd < volume_cfg.get('min_volume_24h_usd', 1000000): # Si volume trop bas
                 # On pourrait r√©duire le signal ou l'ignorer. LTB le boostait.
                 # Ici, on va suivre la logique de LTB qui booste si volume √©lev√©.
                 pass # Ne rien faire si volume bas, LTB boostait si volume HAUT.
            else: # Volume est HAUT (ou au moins pas bas)
                 modified_signal *= volume_cfg.get('signal_boost_factor', 1.1)
                 logger.debug(f"Filtre volume (boost) appliqu√© pour {symbol}. Volume: {volume_24h_usd:.2f}. Signal: {modified_signal:.3f}")
        
        # Validation finale du signal modifi√©
        if np.isnan(modified_signal) or np.isinf(modified_signal):
            logger.error(f"Signal filtr√© invalide pour {symbol}: {modified_signal}, retour au signal original: {signal}")
            modified_signal = signal
        
        return max(-1.0, min(1.0, modified_signal)) # Assurer que le signal reste dans [-1, 1]

    def _check_risk_limits(self, symbol: str, signal: float) -> bool:
        """V√©rifie si le trade respecte les limites de risque"""
        try:
            # V√©rifier les limites du risk manager
            current_exposure = self._calculate_current_exposure()
            max_exposure = self.config['initial_capital'] * self.config['max_total_exposure']
            
            if current_exposure >= max_exposure:
                logger.warning(f"Exposition maximale atteinte: {current_exposure:.2f}")
                return False
            
            # V√©rifier les pertes journali√®res
            if self.stats['pnl_today'] <= -self.config['initial_capital'] * self.config['max_daily_loss']:
                logger.warning(f"Limite de perte journali√®re atteinte: {self.stats['pnl_today']:.2f}")
                return False
            
            # TODO: V√©rifier d'autres limites sp√©cifiques au symbole si n√©cessaire
            
            return True
            
        except Exception as e:
            logger.error(f"Erreur lors de la v√©rification des risques: {e}")
            self.stats['errors'] += 1
            return False
    
    async def _execute_buy_signal(self, symbol: str, signal: float, price: float):
        """Ex√©cute un signal d'achat"""
        try:
            # Calculer la taille de position
            position_value = self._calculate_position_size(symbol, signal)
            quantity = position_value / price
            
            # Arrondir la quantit√© selon les r√®gles de Binance
            quantity = self._round_quantity(symbol, quantity)
            
            if quantity > 0:
                order = TradingOrder(
                    symbol=symbol,
                    side=OrderSide.BUY,
                    order_type=OrderType.MARKET,
                    quantity=quantity,
                    client_order_id=f"buy_{symbol}_{int(time.time())}"
                )
                
                # Placer l'ordre
                success = await self.trader.place_order_async(order) # place_order_async retourne un bool√©en
                if success: # success signifie que l'ordre a √©t√© accept√© par l'API (ou simul√© avec succ√®s)
                    logger.info(f"üü¢ Ordre d'achat soumis: {symbol} - {quantity:.6f} @ market (ref price {price:.4f})")
                    # Les stats de trades ex√©cut√©s/r√©ussis seront mises √† jour dans _on_order_update
                else:
                    self.stats['failed_trades'] += 1
                    logger.error(f"√âchec de la soumission de l'ordre d'achat pour {symbol}")

        except Exception as e:
            logger.error(f"Erreur lors de l'ex√©cution du signal d'achat: {e}")
            self.stats['errors'] += 1
            self.stats['failed_trades'] += 1
    
    async def _execute_sell_signal(self, symbol: str, signal: float, price: float):
        """Ex√©cute un signal de vente"""
        try:
            # V√©rifier la position actuelle
            current_balance = self.trader.account_balances.get(symbol.replace('USDT', ''), None)
            if not current_balance or current_balance.free <= 0:
                logger.debug(f"Pas de position √† vendre pour {symbol}")
                return
            
            # Calculer la quantit√© √† vendre
            sell_percentage = min(abs(signal), 1.0)  # Vendre selon la force du signal
            quantity = current_balance.free * sell_percentage
            quantity = self._round_quantity(symbol, quantity)
            
            if quantity > 0:
                order = TradingOrder(
                    symbol=symbol,
                    side=OrderSide.SELL,
                    order_type=OrderType.MARKET,
                    quantity=quantity,
                    client_order_id=f"sell_{symbol}_{int(time.time())}"
                )
                
                # Placer l'ordre
                success = await self.trader.place_order_async(order)
                if success:
                    logger.info(f"üî¥ Ordre de vente soumis: {symbol} - {quantity:.6f} @ market (ref price {price:.4f})")
                else:
                    self.stats['failed_trades'] += 1
                    logger.error(f"√âchec de la soumission de l'ordre de vente pour {symbol}")
                
        except Exception as e:
            logger.error(f"Erreur lors de l'ex√©cution du signal de vente: {e}")
            self.stats['errors'] += 1
            self.stats['failed_trades'] += 1
    
    def _calculate_position_size(self, symbol: str, signal: float) -> float:
        """Calcule la taille de position en fonction du signal"""
        # Taille de base proportionnelle au signal
        base_size = self.config['initial_capital'] * self.config['max_position_size']
        position_size = base_size * abs(signal)
        
        # Limiter la taille maximale
        max_position = self.config['initial_capital'] * self.config['max_position_size']
        return min(position_size, max_position)
    
    def _round_quantity(self, symbol: str, quantity: float) -> float:
        """Arrondit la quantit√© selon les r√®gles de Binance"""
        # R√®gles simplifi√©es - dans un vrai syst√®me, utiliser les exchange info
        if 'USDT' in symbol:
            if 'BTC' in symbol:
                return round(quantity, 6)
            elif 'ETH' in symbol:
                return round(quantity, 5)
            else:
                return round(quantity, 4)
        return round(quantity, 8)
    
    def _calculate_current_exposure(self) -> float:
        """Calcule l'exposition actuelle du portfolio"""
        total_value = 0.0
        
        for asset, balance in self.trader.account_balances.items():
            if balance.total > 0 and asset != 'USDT':
                # Estimer la valeur en USDT (simplifi√©)
                # Dans un vrai syst√®me, utiliser les prix de march√© actuels
                estimated_price = 100  # Placeholder
                total_value += balance.total * estimated_price
        
        return total_value
    
    async def _model_updater(self):
        """Met √† jour le mod√®le ML p√©riodiquement"""
        logger.info("üß† D√©marrage du gestionnaire de mod√®le")
        
        while self.is_running:
            try:
                # Attendre l'intervalle de mise √† jour
                await asyncio.sleep(self.model_update_interval)
                
                # V√©rifier si une mise √† jour est n√©cessaire
                if self._should_update_model():
                    await self._retrain_model()
                
            except Exception as e:
                logger.error(f"Erreur dans le gestionnaire de mod√®le: {e}")
    
    def _should_update_model(self) -> bool:
        """D√©termine si le mod√®le doit √™tre mis √† jour"""
        if self.last_model_update is None:
            return True
        
        time_since_update = datetime.now() - self.last_model_update
        return time_since_update.total_seconds() >= self.model_update_interval
    
    async def _retrain_model(self):
        """R√©entra√Æne le mod√®le avec les nouvelles donn√©es"""
        try:
            logger.info("üîÑ R√©entra√Ænement du mod√®le en cours...")
            
            # Collecter des donn√©es r√©centes pour tous les symboles
            all_data = []
            for symbol in self.trading_pairs:
                data = await self._get_recent_market_data(symbol, limit=500)
                if data is not None:
                    data = self._calculate_features(data)
                    data['symbol'] = symbol
                    all_data.append(data)
            
            if not all_data:
                logger.warning("Pas de donn√©es pour r√©entra√Æner le mod√®le")
                return
            
            # Combiner toutes les donn√©es
            combined_data = pd.concat(all_data, ignore_index=True)
            combined_data = combined_data.dropna()
            
            if len(combined_data) < 100:
                logger.warning("Donn√©es insuffisantes pour le r√©entra√Ænement")
                return
            
            # Pr√©parer les donn√©es pour l'entra√Ænement
            from src.modeling.models import train_model
            exclude_cols = ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'symbol', 'interval']
            feature_cols = [col for col in combined_data.columns if col not in exclude_cols]
            
            X, y = prepare_data_for_model(
                combined_data,
                target_shift_days=1,
                feature_columns=feature_cols,
                price_change_threshold=0.01
            )
            
            # R√©entra√Æner les mod√®les (ensemble ou mod√®le unique)
            ensemble_enabled = self.config['model'].get('ensemble_enabled', False)
            
            if ensemble_enabled and 'models' in self.config['model']:
                # R√©entra√Æner tous les mod√®les de l'ensemble
                logger.info("üîÑ R√©entra√Ænement de l'ensemble de mod√®les...")
                retrained_models = 0
                total_accuracy = 0.0
                
                for model_config in self.config['model']['models']:
                    if not model_config.get('enabled', True):
                        continue
                        
                    model_name = model_config['name']
                    model_path = model_config['path']
                    model_type = self._get_model_type_from_path(model_path)
                    
                    try:
                        logger.info(f"R√©entra√Ænement du mod√®le {model_name} ({model_type})...")
                        
                        # Adapter les param√®tres selon le type de mod√®le
                        model_params = self._get_model_params_for_type(model_type)
                        scale_features = model_type in ['logistic_regression', 'elastic_net']
                        
                        metrics = train_model(
                            X, y,
                            model_type=model_type,
                            model_params=model_params,
                            model_path=model_path,
                            scale_features=scale_features
                        )
                        
                        accuracy = metrics.get('accuracy', 0.0)
                        total_accuracy += accuracy
                        retrained_models += 1
                        
                        logger.info(f"‚úÖ Mod√®le {model_name} r√©entra√Æn√©. Accuracy: {accuracy:.3f}")
                        
                    except Exception as e:
                        logger.error(f"‚ùå Erreur lors du r√©entra√Ænement de {model_name}: {e}")
                        continue
                
                if retrained_models > 0:
                    avg_accuracy = total_accuracy / retrained_models
                    logger.info(f"‚úÖ Ensemble r√©entra√Æn√©: {retrained_models} mod√®les, accuracy moyenne: {avg_accuracy:.3f}")
                else:
                    logger.error("‚ùå Aucun mod√®le de l'ensemble n'a pu √™tre r√©entra√Æn√©")
                    
            else:
                # Mode mod√®le unique (comportement original)
                model_path = self.config['model'].get('model_path', 'models_store/logistic_regression_mvp.joblib')
                metrics = train_model(
                    X, y,
                    model_type='logistic_regression',
                    model_path=model_path,
                    scale_features=True
                )
                logger.info(f"‚úÖ Mod√®le unique r√©entra√Æn√©. Accuracy: {metrics.get('accuracy', 'N/A'):.3f}")
            
            self.last_model_update = datetime.now()
            self.stats['last_model_retrain_time'] = self.last_model_update
            
        except Exception as e:
            logger.error(f"Erreur lors du r√©entra√Ænement du mod√®le: {e}")
            self.stats['errors'] += 1
    
    def _get_model_type_from_path(self, model_path: str) -> str:
        """Extrait le type de mod√®le du nom de fichier"""
        filename = model_path.lower()
        
        if 'logistic_regression' in filename or 'logistic' in filename:
            return 'logistic_regression'
        elif 'elasticnet' in filename or 'elastic_net' in filename:
            return 'elastic_net'
        elif 'random_forest' in filename or 'rf' in filename:
            return 'random_forest'
        elif 'xgb' in filename or 'xgboost' in filename:
            return 'xgboost_classifier'
        elif 'quantile' in filename:
            return 'quantile_regression'
        else:
            # Fallback par d√©faut
            logger.warning(f"Type de mod√®le non reconnu pour {model_path}, utilisation de logistic_regression par d√©faut")
            return 'logistic_regression'
    
    def _get_model_params_for_type(self, model_type: str) -> Dict:
        """Retourne les param√®tres appropri√©s pour chaque type de mod√®le"""
        params = {
            'logistic_regression': {
                'solver': 'liblinear',
                'max_iter': 1000,
                'C': 1.0,
                'penalty': 'l2'
            },
            'elastic_net': {
                'loss': 'log_loss',
                'penalty': 'elasticnet',
                'max_iter': 1000,
                'tol': 1e-3,
                'alpha': 0.0001,
                'l1_ratio': 0.15
            },
            'random_forest': {
                'n_estimators': 100,
                'max_depth': 10,
                'min_samples_split': 5,
                'min_samples_leaf': 2,
                'n_jobs': -1,
                'ccp_alpha': 0.0
            },
            'xgboost_classifier': {
                'objective': 'binary:logistic',
                'eval_metric': 'logloss',
                'n_estimators': 100,
                'max_depth': 6,
                'learning_rate': 0.1,
                'subsample': 0.8,
                'colsample_bytree': 0.8
            },
            'quantile_regression': {
                'loss': 'quantile',
                'alpha': 0.5,
                'n_estimators': 100,
                'max_depth': 6,
                'learning_rate': 0.1
            }
        }
        
        return params.get(model_type, {})
    
    async def _performance_monitor(self):
        """Surveille les performances du trading"""
        logger.info("üìà D√©marrage du moniteur de performance")
        
        while self.is_running:
            try:
                # G√©n√©rer un rapport de performance toutes les heures
                await asyncio.sleep(3600)
                await self._generate_performance_report()
                
            except Exception as e:
                logger.error(f"Erreur dans le moniteur de performance: {e}")
    
    async def _generate_performance_report(self):
        """G√©n√®re un rapport de performance"""
        try:
            uptime = datetime.now() - self.start_time
            
            # R√©cup√©rer le r√©sum√© de trading
            trading_summary = self.trader.get_trading_summary()
            
            # Calculer les m√©triques
            total_orders = trading_summary['total_orders']
            fill_rate = trading_summary['fill_rate']
            
            report = f"""
üìä RAPPORT DE PERFORMANCE AlphaBeta808
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚è±Ô∏è  Temps d'activit√©: {uptime}
üìâ Paires actives: {len(self.trading_pairs)}
Signals G√©n√©r√©s: {self.stats['total_signals_generated']}
Signals Trait√©s: {self.stats['total_signals_processed']}
Ordres Ex√©cut√©s (API): {self.stats['total_trades_executed']} (ceci compte les soumissions, pas les fills)
Trades R√©ussis (Filled): {self.stats['successful_trades']}
Trades √âchou√©s (API/Filled): {self.stats['failed_trades']}
üí∞ P&L Journalier (Estim√©): ${self.stats['pnl_today']:.2f}
Exposition Actuelle (Estim√©e): ${self.stats['current_exposure']:.2f}
Erreurs: {self.stats['errors']}
Derni√®re MAJ Mod√®le: {self.stats['last_model_retrain_time']}
Dernier Health Check: {self.stats['last_health_check']}
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            """
            
            logger.info(report)
            
            # Sauvegarder dans un fichier
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_file = f"reports/performance_{timestamp}.txt"
            os.makedirs("reports", exist_ok=True)
            
            with open(report_file, 'w') as f:
                f.write(report)
            
        except Exception as e:
            logger.error(f"Erreur lors de la g√©n√©ration du rapport: {e}")
            self.stats['errors'] += 1
    
    async def _risk_monitor(self):
        """Surveille les risques en continu"""
        logger.info("üõ°Ô∏è D√©marrage du moniteur de risques")
        
        while self.is_running:
            try:
                await asyncio.sleep(300)  # V√©rifier toutes les 5 minutes
                
                # V√©rifier les limites de risque
                if not self._check_risk_limits("", 0):
                    logger.warning("‚ö†Ô∏è Limites de risque d√©pass√©es - R√©duction des positions")
                    await self._reduce_positions()
                
            except Exception as e:
                logger.error(f"Erreur dans le moniteur de risques: {e}")
                self.stats['errors'] += 1
    # Correction de l'indentation: _reduce_positions est une m√©thode de la classe
    async def _reduce_positions(self):
        """R√©duit les positions en cas de d√©passement des limites de risque"""
        try:
            # Annuler tous les ordres en attente
            await self._cancel_all_open_orders()
            
            # Vendre partiellement les positions importantes
            # Utiliser self.stats['open_positions'] pour savoir ce qu'on d√©tient r√©ellement
            # ou self.trader.account_balances qui est mis √† jour par le stream user data.
            logger.info("Tentative de r√©duction des positions en raison du risque.")
            for symbol_held, position_info in list(self.stats['open_positions'].items()): # list() pour copier si on modifie le dict
                if position_info['quantity'] > 0:
                    # Vendre un pourcentage de la position, ex: 50%
                    quantity_to_sell = position_info['quantity'] * 0.5
                    
                    # S'assurer que le symbole est tradable (ex: BTC si on a BTCUSDT)
                    # Le symbol_held est d√©j√† le symbol de la paire (ex: BTCUSDT) si on stocke comme √ßa dans open_positions
                    # Sinon, il faut le reconstruire. Supposons que symbol_held est la paire.
                    
                    quantity_to_sell = self._round_quantity(symbol_held, quantity_to_sell)
                        
                    if quantity_to_sell > 0:
                        logger.info(f"R√©duction de risque: Vente de {quantity_to_sell} de {symbol_held}")
                        order = TradingOrder(
                            symbol=symbol_held,
                            side=OrderSide.SELL,
                            order_type=OrderType.MARKET,
                            quantity=quantity_to_sell,
                            client_order_id=f"risk_reduce_{symbol_held}_{int(time.time())}"
                        )
                        await self.trader.place_order_async(order)
                        # La mise √† jour de self.stats['open_positions'] se fera via _on_order_update
                    else:
                        logger.info(f"Quantit√© calcul√©e pour r√©duction de {symbol_held} est nulle ou n√©gative.")
            # Alternative: utiliser self.trader.account_balances
            # for asset, balance in self.trader.account_balances.items():
            #     if balance.total > 0 and asset.upper() != 'USDT':
            #         symbol_pair = f"{asset.upper()}USDT"
            #         if symbol_pair in self.trading_pairs: # S'assurer que c'est une paire qu'on trade
            #             quantity_to_sell = balance.free * 0.5 # Vendre 50% du disponible
            #             quantity_to_sell = self._round_quantity(symbol_pair, quantity_to_sell)
            #             if quantity_to_sell > 0:
            #                 # ... placer l'ordre ...
            
        except Exception as e:
            logger.error(f"Erreur lors de la r√©duction des positions: {e}")
            self.stats['errors'] += 1
    
    async def _cancel_all_open_orders(self):
        """Annule tous les ordres ouverts"""
        try:
            for order in list(self.trader.open_orders.values()):
                await self.trader.cancel_order(order.order_id)
                logger.info(f"‚ùå Ordre annul√©: {order.symbol} - {order.client_order_id}")
        
        except Exception as e:
            logger.error(f"Erreur lors de l'annulation des ordres: {e}")
            self.stats['errors'] += 1
    
    def _update_market_history(self, symbol: str, kline_data: Dict):
        """
        Met √† jour l'historique des donn√©es de march√© pour un symbole √† partir d'une kline.
        kline_data est un dictionnaire attendu de l'API stream de Binance pour les klines.
        Exemple: {'t': 1678886400000, 'o': '25000', 'h': '25100', 'l': '24900', 'c': '25050', 'v': '100', ...}
        """
        try:
            if symbol not in self.market_history:
                self.market_history[symbol] = pd.DataFrame(columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])

            # Convertir les donn√©es de la kline au format attendu par le DataFrame
            # Le timestamp 't' est le d√©but de la kline. 'T' est la fin. On utilise 't'.
            new_data_point = pd.DataFrame([{
                'timestamp': pd.to_datetime(kline_data['t'], unit='ms'),
                'open': float(kline_data['o']),
                'high': float(kline_data['h']),
                'low': float(kline_data['l']),
                'close': float(kline_data['c']),
                'volume': float(kline_data['v']),
                'quote_asset_volume': float(kline_data.get('q', 0)) # Volume de l'asset de cotation
                # Ajouter d'autres champs si n√©cessaire, ex: 'n' (nombre de trades)
            }])

            # Concat√©ner et g√©rer les doublons (bas√© sur le timestamp)
            # Si la kline n'est pas encore ferm√©e, son timestamp de d√©but peut se r√©p√©ter.
            # On ne devrait ajouter que les klines ferm√©es (kline_data['x'] == True)
            if kline_data.get('x', False): # 'x': Is this kline closed?
                # Supprimer l'ancienne entr√©e si elle existe pour ce timestamp pour √©viter les doublons exacts
                self.market_history[symbol] = self.market_history[symbol][self.market_history[symbol]['timestamp'] != new_data_point['timestamp'].iloc[0]]
                self.market_history[symbol] = pd.concat([self.market_history[symbol], new_data_point], ignore_index=True)
                
                # Garder seulement les N derni√®res p√©riodes
                max_periods = self.config['features'].get('feature_lookback_periods', 200) + 100 # Garder un peu plus pour calculs
                if len(self.market_history[symbol]) > max_periods:
                    self.market_history[symbol] = self.market_history[symbol].tail(max_periods).reset_index(drop=True)
                
                # logger.debug(f"Historique march√© pour {symbol} mis √† jour avec kline @ {new_data_point['timestamp'].iloc[0]}. Taille: {len(self.market_history[symbol])}")
            # else:
                # logger.debug(f"Kline non ferm√©e pour {symbol} @ {pd.to_datetime(kline_data['t'], unit='ms')}, non ajout√©e √† l'historique principal.")

        except Exception as e:
            logger.error(f"Erreur lors de la mise √† jour de l'historique de march√© pour {symbol}: {e}")
            self.stats['errors'] += 1

    async def _on_market_data(self, market_data: MarketData):
        """
        Callback pour les donn√©es de march√© (flux de klines).
        market_data est un objet MarketData qui contient .data (le dictionnaire de la kline).
        """
        try:
            # market_data.data contient les informations de la kline du stream
            # ex: {'e': 'kline', 'E': 1678886460000, 's': 'BTCUSDT', 'k': {'t': 1678886400000, 'T': 1678886459999, 's': 'BTCUSDT', 'i': '1m', 'f': 100, 'L': 200, 'o': '0.0010', 'c': '0.0020', 'h': '0.0025', 'l': '0.0015', 'v': '1000', 'n': 100, 'x': False, 'q': '1.0000', 'V': '500', 'Q': '0.500', 'B': '123456'}}
            if market_data and market_data.data and 'k' in market_data.data:
                kline_details = market_data.data['k']
                symbol = market_data.data['s']
                
                # Mettre √† jour l'historique de march√© uniquement avec les klines ferm√©es
                if kline_details.get('x', False): # 'x' est le bool√©en "is kline closed?"
                    self._update_market_history(symbol, kline_details)
                    # On pourrait d√©clencher une analyse ici si la kline est ferm√©e,
                    # au lieu d'attendre le _market_scanner.
                    # Cela rendrait le bot plus r√©actif.
                    # await self._analyze_symbol(symbol) # Attention, _analyze_symbol est d√©j√† appel√© par _market_scanner
                                                       # Il faudrait une logique pour √©viter les analyses concurrentes ou redondantes.
                                                       # Pour l'instant, on laisse _market_scanner faire son travail √† intervalle r√©gulier.
                # else:
                    # logger.debug(f"Kline non ferm√©e re√ßue pour {symbol}: o={kline_details['o']}, c={kline_details['c']}")
                    # On pourrait stocker ces klines non ferm√©es pour une vue "temps r√©el" si besoin.
            else:
                logger.warning(f"Donn√©es de march√© re√ßues dans un format inattendu: {market_data.data if market_data else 'None'}")

        except Exception as e:
            logger.error(f"Erreur dans _on_market_data pour {market_data.symbol if market_data else 'N/A'}: {e}")
            self.stats['errors'] += 1
    
    async def _on_order_update(self, order: TradingOrder):
        """Callback pour les mises √† jour d'ordres"""
        logger.info(f"Mise √† jour d'ordre re√ßue: ID {order.order_id}, ClientID {order.client_order_id}, Symbole {order.symbol}, Statut {order.status.value}, Quantit√© Remplie {order.filled_quantity}, Prix Moyen {order.avg_fill_price}")
        self.stats['total_trades_executed'] +=1 # Compte chaque tentative de trade (soumission)

        if order.status == OrderStatus.FILLED:
            self.stats['successful_trades'] += 1
            logger.info(f"‚úÖ Ordre ex√©cut√© et rempli: {order.symbol} {order.side.value} {order.filled_quantity:.6f} @ {order.avg_fill_price:.4f}")
            
            # Mettre √† jour P&L et positions (simplifi√©)
            # Un vrai calcul de P&L n√©cessite de tracker le co√ªt d'acquisition.
            # Pour l'instant, on va juste compter les trades.
            # On pourrait aussi mettre √† jour self.stats['open_positions']
            if order.side == OrderSide.BUY:
                if order.symbol not in self.stats['open_positions']:
                    self.stats['open_positions'][order.symbol] = {'quantity': 0, 'entry_price_sum': 0}
                self.stats['open_positions'][order.symbol]['quantity'] += order.filled_quantity
                self.stats['open_positions'][order.symbol]['entry_price_sum'] += order.filled_quantity * order.avg_fill_price
            elif order.side == OrderSide.SELL:
                if order.symbol in self.stats['open_positions'] and self.stats['open_positions'][order.symbol]['quantity'] > 0:
                    # Calcul simple du P&L pour cette vente
                    avg_buy_price = self.stats['open_positions'][order.symbol]['entry_price_sum'] / self.stats['open_positions'][order.symbol]['quantity']
                    pnl_trade = (order.avg_fill_price - avg_buy_price) * order.filled_quantity
                    self.stats['pnl_today'] += pnl_trade
                    logger.info(f"Trade de vente pour {order.symbol} P&L: {pnl_trade:.2f}")
                    self.stats['open_positions'][order.symbol]['quantity'] -= order.filled_quantity
                    self.stats['open_positions'][order.symbol]['entry_price_sum'] -= order.filled_quantity * avg_buy_price # Ajuster la somme
                    if self.stats['open_positions'][order.symbol]['quantity'] <= 0.000001: # Tol√©rance pour float
                        del self.stats['open_positions'][order.symbol]
                else: # Vente √† d√©couvert ou vente sans position track√©e
                    logger.warning(f"Vente de {order.symbol} sans position d'achat track√©e.")


        elif order.status in [OrderStatus.CANCELED, OrderStatus.REJECTED, OrderStatus.EXPIRED]:
            self.stats['failed_trades'] += 1
            logger.warning(f"‚ö†Ô∏è Ordre non abouti: {order.symbol} {order.side.value}, Statut: {order.status.value}, Raison: {order.reject_reason if order.reject_reason else 'N/A'}")
    
    async def _on_account_update(self, balances: Dict[str, any]):
        """Callback pour les mises √† jour de compte"""
        # Mettre √† jour l'exposition totale, P&L, etc.
        # logger.debug(f"Mise √† jour du compte re√ßue: {balances}")
        # Cette fonction est appel√©e par BinanceRealTimeTrader avec les balances.
        # On peut l'utiliser pour mettre √† jour self.stats['current_exposure']
        # et potentiellement un P&L plus pr√©cis si on a les prix actuels.
        current_exposure_val = 0
        if self.trader: # S'assurer que trader est initialis√©
            for asset, balance_info in self.trader.account_balances.items(): # Utiliser les balances stock√©es dans trader
                if asset.upper() != 'USDT' and balance_info.total > 0:
                    symbol_pair = f"{asset.upper()}USDT"
                    # Essayer d'obtenir le prix actuel pour l'√©valuation
                    # Pourrait utiliser self.market_history ou un appel ticker
                    current_price = None
                    if symbol_pair in self.market_history and not self.market_history[symbol_pair].empty:
                        current_price = self.market_history[symbol_pair]['close'].iloc[-1]
                    
                    if current_price:
                        current_exposure_val += balance_info.total * current_price
                    # else: logger.warning(f"Prix non trouv√© pour {symbol_pair} pour calculer l'exposition")

        self.stats['current_exposure'] = current_exposure_val
        # logger.info(f"Exposition actuelle mise √† jour: ${self.stats['current_exposure']:.2f}")
        pass

    def get_status(self) -> Dict:
        """Retourne le statut actuel du bot."""
        uptime_seconds = (datetime.now() - self.stats['start_time']).total_seconds() if self.stats['start_time'] else 0
        
        # Copier les stats pour √©viter les modifications concurrentes pendant la lecture
        current_stats = self.stats.copy()
        current_stats['uptime_seconds'] = uptime_seconds
        current_stats['start_time'] = str(current_stats['start_time']) # S√©rialisable
        if current_stats['last_health_check']:
             current_stats['last_health_check'] = str(current_stats['last_health_check'])
        if current_stats['last_model_retrain_time']:
             current_stats['last_model_retrain_time'] = str(current_stats['last_model_retrain_time'])


        trading_summary = {}
        if self.trader:
            try:
                trading_summary = self.trader.get_trading_summary()
            except Exception as e:
                logger.error(f"Erreur lors de la r√©cup√©ration du trading summary: {e}")
        
        subscribed_symbols = []
        if self.strategy and hasattr(self.strategy, 'trader') and self.strategy.trader:
            subscribed_symbols = list(self.strategy.trader.subscribed_symbols)


        return {
            'is_running': self.is_running,
            'config_name': self.config.get("name", "N/A"), # Si on ajoute un nom √† la config
            'current_time': datetime.now().isoformat(),
            'stats': current_stats,
            'trading_summary': trading_summary,
            'subscribed_symbols': subscribed_symbols,
            'market_history_stats': {
                symbol: {
                    'count': len(df),
                    'last_update': df['timestamp'].iloc[-1].isoformat() if not df.empty else None
                } for symbol, df in self.market_history.items()
            },
            'signal_queue_size': self.signal_queue.qsize(),
            # Ne pas inclure self.config entier ici car il peut contenir des secrets si mal configur√©.
            # Ou alors, filtrer les cl√©s sensibles.
            # 'active_config_subset': {
            #     'trading_pairs': self.config.get('trading_pairs'),
            #     'testnet': self.config.get('testnet'),
            #     'model_path': self.config.get('model', {}).get('model_path')
            # }
        }

async def main():
    """Fonction principale"""
    # Configuration du signal handler pour arr√™t propre
    trader = ContinuousTrader()
    
    def signal_handler(signum, frame):
        logger.info("Signal d'arr√™t re√ßu...")
        asyncio.create_task(trader.stop_trading())
    
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    try:
        # Initialiser et d√©marrer le trader
        await trader.initialize()
        await trader.start_trading()
        
    except KeyboardInterrupt:
        logger.info("Arr√™t demand√© par l'utilisateur")
    except Exception as e:
        logger.error(f"Erreur fatale: {e}")
    finally:
        await trader.stop_trading()

if __name__ == "__main__":
    print("üöÄ AlphaBeta808 Continuous Trading Bot")
    print("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
    print("Trading automatique 24h/24 7j/7")
    print("Ctrl+C pour arr√™ter")
    print("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
    
    asyncio.run(main())
